{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad9286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\sushm\\anaconda3\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (2.7.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d7e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (61.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8723fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\sushm\\anaconda3\\lib\\site-packages (1.24.5)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.3 in c:\\users\\sushm\\anaconda3\\lib\\site-packages (from PyMuPDF) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bf46d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: ['october', 'tasks', 'server', 'bachelor', 'block', '•', 'html', 'd', 'google', 'programming', 'technologies', 'university', 'stage', 'program', 'composite', 'achievements', '2015', 'main', 'personal', 'activities', 'gsss', 'central', '-', 'course', 'vinutha', 'certifications', 'bharatanatyam', '90.6', 'intelligence', 'role', 'e', 'languages', 'company', 'vijaya', 'jss', 'mysql', 'dance', 'lab', '9.11', 'python', 'workshop', 'css', 'birth', 'data', 'user', 'ideathon', 'ec', 'interests', 'craft', 'ai&ml', 'institute', 'karunada', 'inter', 'hunt', 'board', 'puc', '2019', 'webpage', 'active', 'export', '5', 'validation', 'information', 'school', 'technology', '219', 'technical', 'pu', 'technological', 'mail', 'organization', 'j', 'mini', 'teach', 'diy', 'skill', 'women', 'semester', 'form', 'student', '14', '\\n \\n', 'linkedin', 'skills', 'of', 'projects', '872', 'vvce', 'education', 'web', 'record', '2025', 'computer', ',', 'council', 'access', 'day', 'english', 'academy', 'learning', '%', 'feedback', 'for', 'upto', 'gsssietw', 'fields', 'belagavi', 'linux', 'mysuru', '2003', 'deployed', 'artificial', 'beginners', 'karnataka', 'vittala', 'success', 'classical', '25th', 'u&i', 'jp', 'php', 'engineering', 'visvesvaraya', 'nagar', 'hindi', 'development', '97.5', 'address', 'date', 'nie', 'world', 'dashboard', 'knowledge', 'collection', 'c', 'crash', 'cse', 'open', 'art', 'cloud', 'public', 'cross,2nd', 'saina', 'hackathon', 'college', 'contact', '2021', 'code', '22nd', 'kannada', 'project', 'i', 'department', 'guiness', '\\n', 'science', 'strengths', 'and', 'fingertips', 'impact', 'noopura', 'secondary', '2023', 'volunteer', 'machine', 'captain', 'dbms', 'pre', 'group']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def extract_keywords(resume_text):\n",
    "    \"\"\"\n",
    "    Extracts keywords from a given text using spaCy.\n",
    "    \"\"\"\n",
    "    doc = nlp(resume_text)\n",
    "    keywords = set()\n",
    "    for token in doc:\n",
    "        if token.ent_type_ or token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "            keywords.add(token.text.lower())\n",
    "    return list(keywords)\n",
    "\n",
    "# Example PDF file path\n",
    "pdf_path = \"C:\\\\Users\\\\sushm\\\\OneDrive\\\\Desktop\\\\resume\\\\a.pdf\"\n",
    "\n",
    "# Extract text from the PDF\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Extract keywords from the extracted text\n",
    "keywords = extract_keywords(resume_text)\n",
    "print(\"Extracted Keywords:\", keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8d90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords from PDF Resume:\n",
      " ['october', 'tasks', 'server', 'bachelor', 'block', '•', 'html', 'd', 'google', 'programming', 'technologies', 'university', 'stage', 'program', 'composite', 'achievements', '2015', 'main', 'personal', 'activities', 'gsss', 'central', '-', 'course', 'vinutha', 'certifications', 'bharatanatyam', '90.6', 'intelligence', 'role', 'e', 'languages', 'company', 'vijaya', 'jss', 'mysql', 'dance', 'lab', '9.11', 'python', 'workshop', 'css', 'birth', 'data', 'user', 'ideathon', 'ec', 'interests', 'craft', 'ai&ml', 'institute', 'karunada', 'inter', 'hunt', 'board', 'puc', '2019', 'webpage', 'active', 'export', '5', 'validation', 'information', 'school', 'technology', '219', 'technical', 'pu', 'technological', 'mail', 'organization', 'j', 'mini', 'teach', 'diy', 'skill', 'women', 'semester', 'form', 'student', '14', '\\n \\n', 'linkedin', 'skills', 'of', 'projects', '872', 'vvce', 'education', 'web', 'record', '2025', 'computer', ',', 'council', 'access', 'day', 'english', 'academy', 'learning', '%', 'feedback', 'for', 'upto', 'gsssietw', 'fields', 'belagavi', 'linux', 'mysuru', '2003', 'deployed', 'artificial', 'beginners', 'karnataka', 'vittala', 'success', 'classical', '25th', 'u&i', 'jp', 'php', 'engineering', 'visvesvaraya', 'nagar', 'hindi', 'development', '97.5', 'address', 'date', 'nie', 'world', 'dashboard', 'knowledge', 'collection', 'c', 'crash', 'cse', 'open', 'art', 'cloud', 'public', 'cross,2nd', 'saina', 'hackathon', 'college', 'contact', '2021', 'code', '22nd', 'kannada', 'project', 'i', 'department', 'guiness', '\\n', 'science', 'strengths', 'and', 'fingertips', 'impact', 'noopura', 'secondary', '2023', 'volunteer', 'machine', 'captain', 'dbms', 'pre', 'group']\n",
      "\n",
      "Selected Resume-based Questions:\n",
      "Tell me the commands to file handling What are the system handling commands?\n",
      "What are the certifications you have done? what you have learnt from that?\n",
      "What are real time examples of database ?how do wrrite a query to get the total order palced in library management system?\n"
     ]
    }
   ],
   "source": [
    "import random  # Import the random module\n",
    "import json\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Define the function to extract keywords from text\n",
    "def extract_keywords(resume_text):\n",
    "    doc = nlp(resume_text)\n",
    "    keywords = set()\n",
    "    for token in doc:\n",
    "        if token.ent_type_ or token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "            keywords.add(token.text.lower())\n",
    "    return list(keywords)\n",
    "\n",
    "# Example PDF file path\n",
    "pdf_path = \"C:\\\\Users\\\\sushm\\\\OneDrive\\\\Desktop\\\\resume\\\\a.pdf\"\n",
    "\n",
    "# Extract text from the PDF\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Extract keywords from the extracted text using spaCy\n",
    "resume_keywords = extract_keywords(resume_text)\n",
    "print(\"Extracted Keywords from PDF Resume:\\n\", resume_keywords)\n",
    "\n",
    "# Load questions from JSON file\n",
    "with open(\"questions.json\", \"r\") as file:\n",
    "    questions_data = json.load(file)\n",
    "\n",
    "# Select questions based on extracted keywords\n",
    "resume_questions = []\n",
    "\n",
    "# Shuffle the keywords to ensure randomness\n",
    "random.shuffle(resume_keywords)\n",
    "\n",
    "# Track the number of questions added\n",
    "questions_added = 0\n",
    "\n",
    "# Iterate through keywords and select questions\n",
    "for keyword in resume_keywords:\n",
    "    if keyword in questions_data[\"keywords\"]:\n",
    "        for question in questions_data[\"keywords\"][keyword]:\n",
    "            if questions_added < 3:  # Limit to 3 questions\n",
    "                resume_questions.append(question)\n",
    "                questions_added += 1\n",
    "            else:\n",
    "                break  # Exit loop if 3 questions are added\n",
    "\n",
    "# Print selected questions\n",
    "print(\"\\nSelected Resume-based Questions:\")\n",
    "for question in resume_questions:\n",
    "    print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5dcd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "                                           questions  \\\n",
      "0               What are the key features of Python?   \n",
      "1  Can you describe a situation where you worked ...   \n",
      "2   What are the differences between C++ and Python?   \n",
      "3     Tell me the recent project you have worked on?   \n",
      "4         What are the certifications you have done?   \n",
      "\n",
      "                                         user_answer  \\\n",
      "0  Python is known for its simplicity, readabilit...   \n",
      "1  Sure, I worked in a team on a software develop...   \n",
      "2  C++ is a statically typed language with manual...   \n",
      "3  I recently worked on a web application for man...   \n",
      "4  I have certifications in Python programming, w...   \n",
      "\n",
      "                                     expected_answer  \n",
      "0  Python is known for its simplicity, readabilit...  \n",
      "1  Certainly! In my previous role as a software d...  \n",
      "2  C++ and Python are both powerful programming l...  \n",
      "3  In my most recent project, I led a team in dev...  \n",
      "4  I have obtained several certifications to enha...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4c7dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sushm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "Index(['questions', 'user_answer', 'expected_answer'], dtype='object')\n",
      "\n",
      "Missing values in the dataset:\n",
      "questions          0\n",
      "user_answer        0\n",
      "expected_answer    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download NLTK punkt tokenizer resource\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Explore the dataset\n",
    "print(\"Column names in the dataset:\")\n",
    "print(df.columns)\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Preprocess text data\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)  # Remove punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "df['cleaned_text'] = df['user_answer'].apply(clean_text)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['expected_answer'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Now you can proceed to build and train your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4460d16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n",
      "Classification Report:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              precision    recall  f1-score   support\n",
      "\n",
      "Absolutely! In a previous project, I took on the role of team lead and successfully guided my team through a challenging development phase. One instance that stands out is when we encountered a critical issue that threatened to delay the project timeline. I quickly organized a brainstorming session with the team to identify possible solutions and delegated tasks based on each team member's strengths. Through effective communication and collaboration, we were able to resolve the issue within a tight deadline and ensure the project stayed on track. My proactive approach and ability to rally the team in times of crisis demonstrated my leadership skills and commitment to achieving project goals.       0.00      0.00      0.00       0.0\n",
      "                                                       C++ and Python are both powerful programming languages with distinct characteristics. C++ is a statically typed language with manual memory management, making it well-suited for performance-critical applications such as system-level programming and game development. On the other hand, Python is dynamically typed with automatic memory management, prioritizing simplicity and readability. Python's interpreted nature and extensive libraries make it ideal for rapid prototyping, web development, and data analysis. While C++ offers greater control over memory and performance optimization, Python excels in developer productivity and ease of use.       0.00      0.00      0.00       0.0\n",
      "                                                                                                                                                                                                                           Certainly! In my previous role as a software developer, I worked closely with a cross-functional team to develop a new product feature. During this project, I actively participated in team meetings, contributed ideas for solution design, and collaborated with team members to address challenges and meet project deadlines. By fostering open communication and leveraging each team member's strengths, we successfully delivered the feature on time and exceeded customer expectations.       0.00      0.00      0.00       1.0\n",
      "                                                                                                                                                    Real-time examples of databases include enterprise systems such as Customer Relationship Management (CRM) software, Online Transaction Processing (OLTP) systems, and Inventory Management Systems. These databases are crucial for storing and managing large volumes of data in real-time, enabling businesses to make informed decisions and provide responsive services to customers. For example, a CRM system tracks customer interactions and preferences in real-time, allowing businesses to personalize marketing campaigns and improve customer satisfaction.       0.00      0.00      0.00       1.0\n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    accuracy                           0.00       2.0\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   macro avg       0.00      0.00      0.00       2.0\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sushm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sushm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sushm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sushm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sushm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sushm\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries for building and training the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Build the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model for future use\n",
    "import joblib\n",
    "joblib.dump(model, 'interview_bot_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bb8c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Interview Bot!\n",
      "Question: What are the key features of Python?\n",
      "Please enter your answer: yes\n",
      "Expected answer: Python is known for its simplicity, readability, and versatility. Its elegant syntax allows for concise and expressive code, making it easy to learn and use. Python's extensive standard library provides support for a wide range of tasks, including web development, data analysis, and machine learning. Additionally, Python's dynamic typing and automatic memory management contribute to its efficiency and productivity.\n",
      "Do you want to go to the next question? (yes/no): yes\n",
      "Question: Can you describe a situation where you worked in a team?\n",
      "Please enter your answer: yes\n",
      "Expected answer: Certainly! In my previous role as a software developer, I worked closely with a cross-functional team to develop a new product feature. During this project, I actively participated in team meetings, contributed ideas for solution design, and collaborated with team members to address challenges and meet project deadlines. By fostering open communication and leveraging each team member's strengths, we successfully delivered the feature on time and exceeded customer expectations.\n",
      "Do you want to go to the next question? (yes/no): no\n",
      "Thank you for using the Interview Bot!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('interview_bot_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Define the clean_text function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)  # Remove punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# Function to predict the answer\n",
    "def predict_answer(user_answer):\n",
    "    cleaned_answer = clean_text(user_answer)\n",
    "    transformed_answer = tfidf_vectorizer.transform([cleaned_answer])\n",
    "    predicted_answer = model.predict(transformed_answer)\n",
    "    return predicted_answer[0]\n",
    "\n",
    "# Main interaction loop\n",
    "def main():\n",
    "    print(\"Welcome to the Interview Bot!\")\n",
    "    question_index = 0\n",
    "\n",
    "    while question_index < len(df):\n",
    "        question = df.iloc[question_index]['questions']\n",
    "        expected_answer = df.iloc[question_index]['expected_answer']\n",
    "        \n",
    "        print(f\"Question: {question}\")\n",
    "        user_answer = input(\"Please enter your answer: \")\n",
    "\n",
    "        # Predict the answer using the model\n",
    "        predicted_answer = predict_answer(user_answer)\n",
    "        \n",
    "        # Provide feedback based on the predicted answer\n",
    "       # print(f\"Bot: Your answer seems to be: {predicted_answer}\")\n",
    "        print(f\"Expected answer: {expected_answer}\")\n",
    "        \n",
    "        # Ask if the user wants to continue to the next question\n",
    "        choice = input(\"Do you want to go to the next question? (yes/no): \")\n",
    "        if choice.lower() != \"yes\":\n",
    "            print(\"Thank you for using the Interview Bot!\")\n",
    "            break\n",
    "        \n",
    "        question_index += 1\n",
    "\n",
    "    if question_index >= len(df):\n",
    "        print(\"You have answered all the questions. Thank you for using the Interview Bot!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b0bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Interview Bot!\n",
      "Bot: Here is your question:\n",
      "What are the differences between C++ and Python?\n",
      "Please enter your answer: \n",
      "yes\n",
      "\n",
      "Bot: The expected answer is: C++ and Python are both powerful programming languages with distinct characteristics. C++ is a statically typed language with manual memory management, making it well-suited for performance-critical applications such as system-level programming and game development. On the other hand, Python is dynamically typed with automatic memory management, prioritizing simplicity and readability. Python's interpreted nature and extensive libraries make it ideal for rapid prototyping, web development, and data analysis. While C++ offers greater control over memory and performance optimization, Python excels in developer productivity and ease of use.\n",
      "\n",
      "\n",
      "Bot: Your similarity score is: 0.0\n",
      "\n",
      "\n",
      "Bot: Your score for this answer is: 50\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('interview_bot_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Load the dataset to get questions and expected answers\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Define the clean_text function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)  # Remove punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# Function to calculate similarity score between two text strings\n",
    "def calculate_similarity(user_answer, expected_answer):\n",
    "    user_vector = tfidf_vectorizer.transform([user_answer])\n",
    "    expected_vector = tfidf_vectorizer.transform([expected_answer])\n",
    "    similarity_score = cosine_similarity(user_vector, expected_vector)[0][0]\n",
    "    return similarity_score\n",
    "\n",
    "# Function to calculate score based on similarity score\n",
    "def calculate_score(similarity_score):\n",
    "    # Define scoring algorithm (adjust weights and thresholds as needed)\n",
    "    if similarity_score >= 0.9:\n",
    "        return 100\n",
    "    elif similarity_score >= 0.8:\n",
    "        return 90\n",
    "    elif similarity_score >= 0.7:\n",
    "        return 80\n",
    "    elif similarity_score >= 0.6:\n",
    "        return 70\n",
    "    else:\n",
    "        return 50  # Assign a base score to encourage improvement\n",
    "\n",
    "# Main interaction loop\n",
    "def main():\n",
    "    print(\"Welcome to the Interview Bot!\")\n",
    "    \n",
    "    while True:\n",
    "        # Pick a random question from the dataset\n",
    "        random_question_idx = random.randint(0, len(df) - 1)\n",
    "        question = df.iloc[random_question_idx]['questions']\n",
    "        expected_answer = df.iloc[random_question_idx]['expected_answer']\n",
    "        \n",
    "        print(\"Bot: Here is your question:\")\n",
    "        print(question)\n",
    "        \n",
    "        user_answer = input(\"Please enter your answer: \\n\")\n",
    "\n",
    "        # Predict the answer using the model (optional)\n",
    "        predicted_answer = clean_text(user_answer)  # Clean user's answer\n",
    "        \n",
    "        # Calculate similarity score between user's answer and expected answer\n",
    "        similarity_score = calculate_similarity(predicted_answer, expected_answer)\n",
    "        \n",
    "        # Calculate score based on similarity score\n",
    "        score = calculate_score(similarity_score)\n",
    "        \n",
    "        # Provide feedback, display the expected answer and score\n",
    "        print(\"\\nBot: The expected answer is:\", expected_answer)\n",
    "        print(\"\\n\")\n",
    "        print(\"Bot: Your similarity score is:\", similarity_score)\n",
    "        print(\"\\n\")\n",
    "        print(\"Bot: Your score for this answer is:\", score)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Ask another question or end the conversation\n",
    "        choice = input(\"Do you want another question? (yes/no): \")\n",
    "        if choice.lower() != \"yes\":\n",
    "            print(\"Thank you for using the Interview Bot!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884728da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
